{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module used\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import SVC,SVR\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble import StackingRegressor, StackingClassifier\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "from scipy import linalg, special\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import statistics as stat\n",
    "# import seaborn as sns\n",
    "import multiprocess\n",
    "import time\n",
    "from sklearn.ensemble import VotingClassifier, VotingRegressor\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from scipy.linalg import toeplitz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation_base(p,n,rho,beta_gn,sz,sz0):\n",
    "    # complex relationship with fixed true model\n",
    "    from itertools import combinations\n",
    "    p0 = 20; prest = p-p0\n",
    "    interind = np.array([np.array(list(x)) for x in combinations(range(2, len(beta_gn), len(beta_gn)//5), 2)])\n",
    "\n",
    "    z00 = np.random.binomial(n=1, p=0.35, size=n)\n",
    "\n",
    "    # correlated continuous covariates\n",
    "    sig = toeplitz([rho ** i for i in range(p0-1)])\n",
    "    z0 = np.random.multivariate_normal(mean=np.zeros(p0-1), cov=sig, size=n)\n",
    "    Z0 = np.concatenate([z00[:, None], z0], axis=1)\n",
    "    interterm = np.apply_along_axis(lambda x: Z0[:, x[0]] * Z0[:, x[1]], axis=1, arr=interind)\n",
    "    costerm = np.apply_along_axis(lambda x: np.cos(Z0[:,x]),axis = 0, arr = np.unique(interind))\n",
    "    puse0 = 1/(1+(np.exp(-0.2*np.dot(Z0, beta_gn)- 0.1 * interterm.sum(axis=0))))\n",
    "    t0 = np.random.binomial(n=1, p=puse0, size=n)\n",
    "\n",
    "    y0_1 = np.random.normal(loc=sz0 + np.dot(Z0, beta_gn)+interterm.sum(axis=0), scale=1)\n",
    "    y0_0 = np.random.normal(loc=np.dot(Z0, beta_gn)+interterm.sum(axis=0)+costerm.sum(axis = 1), scale=1)\n",
    "    y0 = np.where(t0==1, y0_1, y0_0)\n",
    "\n",
    "    Zaux0 = np.random.normal(0,1,size = (n,prest))\n",
    "\n",
    "    dat0 = pd.DataFrame(np.concatenate([Z0, Zaux0, t0[:, None], y0[:, None]], axis=1), columns=[\"z00\"] + [f\"z{i}0\" for i in range(1, p)] + [\"t0\", \"y0\"])\n",
    "\n",
    "    # time point 2\n",
    "    z01 = z00 + np.random.uniform(size=n)\n",
    "\n",
    "    z1_1 = z0 + 0.1*y0_1[:, np.newaxis]\n",
    "    z1_0 = z0 + 0.1*y0_0[:, np.newaxis]\n",
    "    z1 = np.concatenate([z1_1[t0==1, :], z1_0[t0==0, :]], axis=0)\n",
    "\n",
    "    Z1_1 = np.concatenate([z01[:, None], z1_1], axis=1)\n",
    "    Z1_0 = np.concatenate([z01[:, None], z1_0], axis=1)\n",
    "    Z1 = np.concatenate([z01[:, None], z1], axis=1)\n",
    "\n",
    "    interterm1 = np.apply_along_axis(lambda x: Z1[:, x[0]] * Z1[:, x[1]], axis=1, arr=interind)\n",
    "    costerm1 = np.apply_along_axis(lambda x:np.cos(Z1[:,x]),axis = 0, arr = np.unique(interind))\n",
    "    puse1 = 1/(1+np.exp(-0.1*np.dot(Z1, beta_gn)+0.5-0.05*interterm1[range(5,interterm1.shape[0]),:].sum(axis = 0)))\n",
    "    t1 = np.random.binomial(n=1, p=puse1, size=n)\n",
    "\n",
    "    y1_11 = np.random.normal(loc=sz + np.dot(Z1_1, np.concatenate([np.array([0]), beta_gn[1:]]))+0.5*interterm1.sum(axis = 0)+0.5*costerm1.sum(axis = 1), scale=1)\n",
    "    y1_00 = np.random.normal(loc=np.dot(Z1_0, np.concatenate([np.array([0]), beta_gn[1:]]))+0.5*interterm1.sum(axis = 0), scale=1)\n",
    "    y1_10 = np.random.normal(loc=np.dot(Z1_1, np.concatenate([np.array([0]), beta_gn[1:]]))+0.5*interterm1.sum(axis = 0)+0.5*costerm1.sum(axis = 1), scale=1)\n",
    "    y1_01 = np.random.normal(loc=sz + np.dot(Z1_0, np.concatenate([np.array([0]), beta_gn[1:]]))+0.5*interterm1.sum(axis = 0)+0.5*costerm1.sum(axis = 1), scale=1)\n",
    "    y1 = np.where(t0==1, np.where(t1==1, y1_11, y1_10), np.where(t1==0, y1_00, y1_01))\n",
    "\n",
    "    Zaux1 = np.random.normal(0,1,size = (n,prest))\n",
    "\n",
    "    dat1 = pd.DataFrame(np.concatenate([Z1, Zaux1, t1[:, None], y1[:, None]], axis=1), columns=[\"z01\"] + [f\"z{i}1\" for i in range(1, p)] + [\"t1\", \"y1\"])\n",
    "    \n",
    "    full_data = pd.concat([dat0, dat1], axis=1)\n",
    "    return full_data, pd.DataFrame({'y_11': y1_11, 'y_00': y1_00, 'p0': puse0, 'p1':puse1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PS function\n",
    "def ps_train_ensemble(data,Train,Test,features,outcomes,\n",
    "                      include_lg=False, include_el=True, include_xgb=True, include_mlp=False,\n",
    "                      include_l1=False, include_svm=False, include_nb=True,include_rf=False):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    # Train,Test = train_test_split(data,test_size=0.4,random_state=42)\n",
    "    np.random.seed(233)\n",
    "    models = {}\n",
    "    # base learner 1\n",
    "    if include_lg:\n",
    "        lg = linear_model.LogisticRegression()\n",
    "        lg.fit(data[features],data[outcomes])\n",
    "        models['logit'] = lg\n",
    "\n",
    "    # base learner 2\n",
    "    if include_el:\n",
    "        el_class = linear_model.SGDClassifier(penalty='elasticnet',loss='log')\n",
    "        param_grid_el = {'alpha': [0.0001, 0.001, 0.01, 0.1]}\n",
    "        gs_el = GridSearchCV(estimator=el_class,param_grid=param_grid_el,cv=5,scoring='neg_log_loss')\n",
    "        gs_el.fit(Train[features],Train[outcomes])\n",
    "        el_class.set_params(**gs_el.best_params_)\n",
    "        el_class.fit(Test[features],Test[outcomes])\n",
    "        models['enet'] = el_class\n",
    "\n",
    "    # base learner 3\n",
    "    if include_xgb:\n",
    "        param_grid_G = {\n",
    "        'learning_rate': [0.01, 0.1, 1],\n",
    "         'max_depth': [55,65,80],\n",
    "        # 'n_estimators': [100,200,300],\n",
    "        # 'alpha':[0.05,0.1,0.18],\n",
    "        # 'gamma': [1,1.5,1.8]\n",
    "        }\n",
    "        xgb_cls = xgb.XGBClassifier(objective='binary:logistic')\n",
    "        gs_xgb = GridSearchCV(\n",
    "            estimator=xgb_cls,\n",
    "            param_grid=param_grid_G,\n",
    "            cv=5,\n",
    "            scoring='neg_log_loss'\n",
    "        )\n",
    "        gs_xgb.fit(Train[features], Train[outcomes])\n",
    "        xgb_cls.set_params(**gs_xgb.best_params_)\n",
    "        xgb_cls.fit(Test[features], Test[outcomes])\n",
    "        models['xgb'] = xgb_cls\n",
    "\n",
    "    # base learner 4\n",
    "    if include_mlp:\n",
    "        mlp_cls = MLPClassifier()\n",
    "        param_grid_mlpc = {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50,50), (100,100)],\n",
    "        }\n",
    "        gs_mlp = GridSearchCV(estimator=mlp_cls,param_grid=param_grid_mlpc,cv=5,scoring=\"neg_log_loss\")\n",
    "        gs_mlp.fit(Train[features],Train[outcomes])\n",
    "        mlp_cls.set_params(**gs_mlp.best_params_)\n",
    "        mlp_cls.fit(Test[features],Test[outcomes])\n",
    "        models['mlp'] = mlp_cls\n",
    "\n",
    "    if include_l1:\n",
    "        l1_cls = linear_model.LogisticRegression(penalty='l1',solver='saga')\n",
    "        param_grid_l1 = {\n",
    "        'C':[0.1,1,5],\n",
    "        #'max_features': [None, 'sqrt', 'log2']\n",
    "        }\n",
    "        gs_l1 = GridSearchCV(estimator=l1_cls,param_grid=param_grid_l1,cv=5,scoring=\"neg_log_loss\")\n",
    "        gs_l1.fit(Train[features],Train[outcomes])\n",
    "        l1_cls.set_params(**gs_l1.best_params_)\n",
    "        l1_cls.fit(Test[features],Test[outcomes])\n",
    "        models['gbr'] = l1_cls\n",
    "\n",
    "    if include_svm:\n",
    "        svm_c = SVC(kernel='linear',probability=True)\n",
    "        gs_svm = GridSearchCV(estimator=svm_c,param_grid={'C': [0.1,1,10,100]},cv=5,scoring='neg_log_loss')\n",
    "        gs_svm.fit(Train[features],Train[outcomes])\n",
    "        svm_c.set_params(**gs_svm.best_params_)\n",
    "        svm_c.fit(Test[features],Test[outcomes])\n",
    "        models['svm'] = svm_c\n",
    "        \n",
    "    if include_nb:\n",
    "        nb_c = GaussianNB()\n",
    "        param_grid_nb = {\n",
    "            'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1]\n",
    "            }\n",
    "        gs_nb = GridSearchCV(nb_c, param_grid=param_grid_nb, cv=5)\n",
    "        gs_nb.fit(Train[features],Train[outcomes])\n",
    "        nb_c.set_params(**gs_nb.best_params_)\n",
    "        nb_c.fit(Test[features],Test[outcomes])\n",
    "        models['nb'] = nb_c\n",
    "\n",
    "    if include_rf:\n",
    "        rf_c = RandomForestClassifier(random_state = 42)\n",
    "        param_grid_rf = {\n",
    "            'n_estimators':[100,200],\n",
    "            'max_depth':[40,50],\n",
    "            'min_samples_split':[2,5],\n",
    "            }\n",
    "        gs_rf = GridSearchCV(rf_c, param_grid=param_grid_rf, cv=5, scoring='neg_log_loss')\n",
    "        gs_rf.fit(Train[features],Train[outcomes])\n",
    "        rf_c.set_params(**gs_rf.best_params_)\n",
    "        rf_c.fit(Test[features],Test[outcomes])\n",
    "        models['rf'] = rf_c\n",
    "\n",
    "    # meta learner\n",
    "    Q1fit = []\n",
    "    if include_lg:\n",
    "        Q1fit.append(lg.predict_proba(data[features])[:,1].ravel())\n",
    "    if include_el:\n",
    "        Q1fit.append(el_class.predict_proba(data[features])[:,1].ravel())\n",
    "    if include_xgb:\n",
    "        Q1fit.append(xgb_cls.predict_proba(data[features])[:,1].ravel())\n",
    "    if include_mlp:\n",
    "        Q1fit.append(mlp_cls.predict_proba(data[features])[:,1].ravel())\n",
    "    if include_l1:\n",
    "        Q1fit.append(l1_cls.predict_proba(data[features])[:,1].ravel())\n",
    "    if include_svm:\n",
    "        Q1fit.append(svm_c.predict_proba(data[features])[:,1].ravel())\n",
    "    if include_nb:\n",
    "        Q1fit.append(nb_c.predict_proba(data[features])[:,1].ravel())\n",
    "    if include_rf:\n",
    "        Q1fit.append(rf_c.predict_proba(data[features])[:,1].ravel())\n",
    "\n",
    "    cls_stack = linear_model.LogisticRegression()\n",
    "    cls_stack.fit(np.transpose(Q1fit),data[outcomes])\n",
    "\n",
    "    return models, cls_stack\n",
    "\n",
    "def ps_function(data,features,outcomes, lg=False, el=True, xgb=True, mlp=False,\n",
    "                l1=False, svm=False, nb=True,rf=False):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    Train,Test = train_test_split(data,test_size=0.4,random_state=42)\n",
    "    model_tr,stack_tr = ps_train_ensemble(data,Train,Test,features,outcomes, include_lg=lg, include_el=el, include_xgb=xgb, include_mlp=mlp,\n",
    "                                          include_l1=l1, include_svm=svm, include_nb=nb,include_rf=rf)\n",
    "    model_ts,stack_ts = ps_train_ensemble(data,Test,Train,features,outcomes, include_lg=lg, include_el=el, include_xgb=xgb, include_mlp=mlp,\n",
    "                                          include_l1=l1, include_svm=svm, include_nb=nb,include_rf=rf)\n",
    "    return model_tr,model_ts,stack_tr,stack_ts\n",
    "\n",
    "def ps_predict(preddat,features,model_tr,model_ts,stack_tr,stack_ts):\n",
    "    y_pred_tr = {}\n",
    "    for name, model in model_tr.items():\n",
    "        y_pred_tr[name] = model.predict_proba(preddat[features])[:,1].ravel()\n",
    "    Q_base_tr = np.transpose(np.array(list(y_pred_tr.values())))\n",
    "    eta_tr = stack_tr.predict_proba(Q_base_tr)[:,1]\n",
    "\n",
    "    y_pred_ts = {}\n",
    "    for name, model in model_ts.items():\n",
    "        y_pred_ts[name] = model.predict_proba(preddat[features])[:,1].ravel()\n",
    "    Q_base_ts = np.transpose(np.array(list(y_pred_ts.values())))\n",
    "    eta_ts = stack_ts.predict_proba(Q_base_ts)[:,1]\n",
    "\n",
    "    return (eta_tr+eta_ts)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gcomputation function\n",
    "def gcompu_train_ensemble(data,Train,Test,features,outcomes,\n",
    "                          include_lm = True, include_rg = False, \n",
    "                          include_xgb = True, include_mlp = False,\n",
    "                          include_gbr = True):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    # Train,Test = train_test_split(data,test_size=0.4,random_state=42)\n",
    "    np.random.seed(233)\n",
    "    models = {}\n",
    "    # base learner 1\n",
    "    if include_lm:\n",
    "        lm_1 = linear_model.LinearRegression()\n",
    "        lm_1.fit(data[features],data[outcomes])\n",
    "        models['lm'] = lm_1\n",
    "\n",
    "    # base learner 2\n",
    "    if include_rg:\n",
    "        rg_lm = linear_model.Ridge()\n",
    "        param_grid_rg = {'alpha': [0.1, 1, 10]}\n",
    "        gs_rg = GridSearchCV(estimator=rg_lm,param_grid=param_grid_rg,cv=5,scoring=\"neg_mean_absolute_error\")\n",
    "        gs_rg.fit(Train[features],Train[outcomes])\n",
    "        rg_lm.set_params(**gs_rg.best_params_)\n",
    "        rg_lm.fit(Test[features],Test[outcomes])\n",
    "        models['rg'] = rg_lm\n",
    "\n",
    "    # base learner 3\n",
    "    if include_xgb:\n",
    "        param_grid_G = {\n",
    "        'learning_rate': [0.01, 0.1, 1],\n",
    "        'max_depth': [15,20,25,35],\n",
    "        # 'n_estimators': [100, 150,200],\n",
    "        #'alpha':[0.05,0.1,0.18],\n",
    "        #'gamma': [1,1.5,1.8]\n",
    "        }\n",
    "        xgb_lm1_tr = xgb.XGBRegressor()\n",
    "        gs_gcomp1_tr = GridSearchCV(\n",
    "            estimator=xgb_lm1_tr,\n",
    "            param_grid=param_grid_G,\n",
    "            cv=5,\n",
    "            scoring='neg_mean_absolute_error'\n",
    "        )\n",
    "        gs_gcomp1_tr.fit(Train[features], Train[outcomes])\n",
    "        xgb_lm1_tr.set_params(**gs_gcomp1_tr.best_params_)\n",
    "        xgb_lm1_tr.fit(Test[features], Test[outcomes])\n",
    "        models['xgb'] = xgb_lm1_tr\n",
    "\n",
    "    # base learner 4\n",
    "    if include_mlp:\n",
    "        mlp_lm = MLPRegressor()\n",
    "        param_grid_mlpr = {\n",
    "            'hidden_layer_sizes': [ (100,), (150,), (100, 100), (150,150)],\n",
    "            'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "        }\n",
    "        gs_mlp_lm = GridSearchCV(estimator=mlp_lm,param_grid=param_grid_mlpr,cv=5,scoring=\"neg_mean_absolute_error\")\n",
    "        gs_mlp_lm.fit(Train[features],Train[outcomes])\n",
    "        mlp_lm.set_params(**gs_mlp_lm.best_params_)\n",
    "        mlp_lm.fit(Test[features],Test[outcomes])\n",
    "        models['mlp'] = mlp_lm\n",
    "\n",
    "    if include_gbr:\n",
    "        gbr_lm = GradientBoostingRegressor()\n",
    "        param_grid_gbr = {\n",
    "        # 'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.05, 0.1, 0.2],\n",
    "        'max_depth': [15,20,25,35],\n",
    "        #'min_samples_split': [2, 3, 4],\n",
    "        #'min_samples_leaf': [1, 2, 3],\n",
    "        #'max_features': [None, 'sqrt', 'log2']\n",
    "        }\n",
    "        gs_gbr_lm = GridSearchCV(estimator=gbr_lm,param_grid=param_grid_gbr,cv=5,scoring=\"neg_mean_absolute_error\")\n",
    "        gs_gbr_lm.fit(Train[features],Train[outcomes])\n",
    "        gbr_lm.set_params(**gs_gbr_lm.best_params_)\n",
    "        gbr_lm.fit(Test[features],Test[outcomes])\n",
    "        models['gbr'] = gbr_lm\n",
    "\n",
    "    # meta learner\n",
    "    Q1fit = []\n",
    "    if include_lm:\n",
    "        Q1fit.append(lm_1.predict(data[features]).ravel())\n",
    "    if include_rg:\n",
    "        Q1fit.append(rg_lm.predict(data[features]).ravel())\n",
    "    if include_xgb:\n",
    "        Q1fit.append(xgb_lm1_tr.predict(data[features]).ravel())\n",
    "    if include_mlp:\n",
    "        Q1fit.append(mlp_lm.predict(data[features]).ravel())\n",
    "    if include_gbr:\n",
    "        Q1fit.append(gbr_lm.predict(data[features]).ravel())\n",
    "\n",
    "    lm_stack = linear_model.LinearRegression()\n",
    "    lm_stack.fit(np.transpose(Q1fit),data[outcomes])\n",
    "\n",
    "    return models, lm_stack\n",
    "\n",
    "def gcompu_function(data,features,outcomes,lm = True, rg = False, \n",
    "                    xgb = True, mlp = False,gbr = True):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    Train,Test = train_test_split(data,test_size=0.4,random_state=42)\n",
    "    model_tr,stack_tr = gcompu_train_ensemble(data,Train,Test,features,outcomes,\n",
    "                                              include_lm = lm, include_rg = rg, \n",
    "                                              include_xgb = xgb, include_mlp = mlp,include_gbr = gbr)\n",
    "    model_ts,stack_ts = gcompu_train_ensemble(data,Test,Train,features,outcomes,\n",
    "                                              include_lm = lm, include_rg = rg, \n",
    "                                              include_xgb = xgb, include_mlp = mlp,include_gbr = gbr)\n",
    "    return model_tr,model_ts,stack_tr,stack_ts\n",
    "\n",
    "\n",
    "def gcompu_predict(preddat,features,model_tr,model_ts,stack_tr,stack_ts):\n",
    "    y_pred_tr = {}\n",
    "    for name, model in model_tr.items():\n",
    "        y_pred_tr[name] = model.predict(preddat[features]).ravel()\n",
    "    Q_base_tr = np.transpose(np.array(list(y_pred_tr.values())))\n",
    "    eta_tr = stack_tr.predict(Q_base_tr)\n",
    "    y_pred_ts = {}\n",
    "    for name, model in model_ts.items():\n",
    "        y_pred_ts[name] = model.predict(preddat[features]).ravel()\n",
    "    Q_base_ts = np.transpose(np.array(list(y_pred_ts.values())))\n",
    "    eta_ts = stack_ts.predict(Q_base_ts)\n",
    "\n",
    "    return (eta_tr+eta_ts)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coef\n",
    "np.random.seed(123)\n",
    "p0 = 20; \n",
    "beta_gn = np.zeros(p0)\n",
    "selected_indices = np.random.choice(np.arange(p0), size=p0-10, replace=False)\n",
    "beta_gn[selected_indices] = np.random.normal(size=p0-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciton\n",
    "def simulation_loop(b,n = 1000,p = 50,beta_gn = beta_gn):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    print(p)\n",
    "    np.random.seed(123+b)\n",
    "    testdat, paramdat = simulation_base(p,n,0.5,beta_gn,0,0)\n",
    "    phi_data = (np.mean(paramdat['y_11']-paramdat['y_00']))\n",
    "\n",
    "    # estimate pt1 ps\n",
    "    ps0outcome = ['t0']\n",
    "    ps0feature = ['z' + str(x) +'0' for x in range(0,p)]\n",
    "    ps1outcome = ['t1']\n",
    "    ps1feature = np.concatenate((['z' + str(x) +'0' for x in range(0,p)],\n",
    "                                    ['z' + str(x) +'1' for x in range(0,p)],['t0','y0']))\n",
    "    #Train,Test = train_test_split(testdat,test_size = 0.4,random_state=42)\n",
    "\n",
    "    baseps0_tr,baseps0_ts,cls_stack0_tr,cls_stack0_ts = ps_function(testdat,ps0feature,ps0outcome)\n",
    "    enps0 = ps_predict(testdat,ps0feature,baseps0_tr,baseps0_ts,cls_stack0_tr,cls_stack0_ts)\n",
    "\n",
    "    baseps1_tr,baseps1_ts,cls_stack1_tr,cls_stack1_ts = ps_function(testdat,ps1feature,ps1outcome,l1=True,mlp=True)\n",
    "    enps1 = ps_predict(testdat,ps1feature,baseps1_tr,baseps1_ts,cls_stack1_tr,cls_stack1_ts)\n",
    "\n",
    "\n",
    "\n",
    "    ## outcome regression ensemble\n",
    "    iter1feature = ['z{}{}'.format(i, j) for i in range(p) for j in range(2)] + ['y0', 't0', 't1']\n",
    "    iter1outcome = ['y1']\n",
    "    iter0feature = ['t0']+['z' + str(x) +'0' for x in range(0,p)]\n",
    "\n",
    "    preddat11 = testdat.copy(); preddat11['t0']=1;preddat11['t1']=1\n",
    "    preddat00 = testdat.copy(); preddat00['t0']=0;preddat00['t1']=0\n",
    "    \n",
    "    basemodel1_tr,basemodel1_ts,lm_stack1_tr,lm_stack1_ts = gcompu_function(testdat,iter1feature,iter1outcome)\n",
    "\n",
    "    eta2 = gcompu_predict(testdat,iter1feature,basemodel1_tr,basemodel1_ts,lm_stack1_tr,lm_stack1_ts)\n",
    "    \n",
    "    \n",
    "\n",
    "    # G-computation\n",
    "     ## G-comp with LR\n",
    "    lm1 = linear_model.LinearRegression()\n",
    "    lm1.fit(testdat[iter1feature],testdat[iter1outcome])\n",
    "    Q11 = lm1.predict(preddat11[iter1feature])\n",
    "    Q00 = lm1.predict(preddat00[iter1feature])\n",
    "\n",
    "    lm0_1 = linear_model.LinearRegression()\n",
    "    lm0_1.fit(testdat[iter0feature],Q11)\n",
    "    lm0_0 = linear_model.LinearRegression()\n",
    "    lm0_0.fit(testdat[iter0feature],Q00)\n",
    "    phi_gcomp_lm = (np.mean(lm0_1.predict(preddat11[iter0feature])-lm0_0.predict(preddat00[iter0feature])))\n",
    "\n",
    "    ## DR\n",
    "    \n",
    "    #eta2 = lm_stack.predict(Q1fit)\n",
    "\n",
    "    preddat1 = testdat.copy(); preddat1['t1']=1\n",
    "    preddat0 = testdat.copy(); preddat0['t1']=0\n",
    "\n",
    "\n",
    "    eta20 = gcompu_predict(preddat0,iter1feature,basemodel1_tr,basemodel1_ts,lm_stack1_tr,lm_stack1_ts)\n",
    "    \n",
    "    basemodel20_tr,basemodel20_ts,lm_stack20_tr,lm_stack20_ts = gcompu_function(pd.concat([testdat, pd.DataFrame(eta20.reshape(n,), columns=['eta20'])], axis=1),\n",
    "                                                    iter0feature,'eta20')\n",
    "\n",
    "    eta21 = gcompu_predict(preddat1,iter1feature,basemodel1_tr,basemodel1_ts,lm_stack1_tr,lm_stack1_ts)\n",
    "    \n",
    "    basemodel21_tr,basemodel21_ts,lm_stack21_tr,lm_stack21_ts = gcompu_function(pd.concat([testdat, pd.DataFrame(eta21.reshape(n,), columns=['eta21'])], axis=1),\n",
    "                                                    iter0feature,'eta21')\n",
    "\n",
    "\n",
    "    Q_00= gcompu_predict(preddat00,iter0feature,basemodel20_tr,basemodel20_ts,lm_stack20_tr,lm_stack20_ts)\n",
    "\n",
    "    Q_11= gcompu_predict(preddat11,iter0feature,basemodel21_tr,basemodel21_ts,lm_stack21_tr,lm_stack21_ts)\n",
    "\n",
    "    phi_gcomp = (np.mean(Q_11-Q_00))\n",
    "            \n",
    "\n",
    "    eta10 = gcompu_predict(preddat0,iter0feature,basemodel20_tr,basemodel20_ts,lm_stack20_tr,lm_stack20_ts)\n",
    "\n",
    "    eta11 = gcompu_predict(preddat1,iter0feature,basemodel21_tr,basemodel21_ts,lm_stack21_tr,lm_stack21_ts)\n",
    "\n",
    "    eta0_00 = Q_00\n",
    "\n",
    "    preddat10 = testdat.copy(); preddat10['t0']=1;preddat10['t1']=0\n",
    "    eta0_10 = gcompu_predict(preddat10,iter0feature,basemodel20_tr,basemodel20_ts,lm_stack20_tr,lm_stack20_ts)\n",
    "\n",
    "    eta0_11 = Q_11\n",
    "\n",
    "    preddat01 = testdat.copy(); preddat01['t0']=0;preddat01['t1']=1\n",
    "    eta0_01 = gcompu_predict(preddat01,iter0feature,basemodel21_tr,basemodel21_ts,lm_stack21_tr,lm_stack21_ts)\n",
    "\n",
    "\n",
    "    ## linear equation for DR, subject to change based on MSM/other outcome equation of interest\n",
    "    t0 = testdat['t0']; t1= testdat['t1']; y1 = testdat['y1']; y0 = testdat['y0']\n",
    "    f01 = ((t0/enps0+(1-t0)/(1-enps0))*(t1/enps1+(1-t1)/(1-enps1))*(y1-eta2.ravel()))\n",
    "    f02 = 1/((enps0**t0)*(1-enps0)**(1-t0))*(eta20.ravel()-eta10.ravel())+1/((enps0**t0)*(1-enps0)**(1-t0))*(eta21.ravel()-eta11.ravel())\n",
    "    f03 = (eta0_00+eta0_11+eta0_10.ravel()+eta0_01.ravel())\n",
    "    c0 = np.mean(f01+f02+f03)\n",
    "    b0 = [4,2,2]\n",
    "\n",
    "    f11 = (t0/enps0+(1-t0)/(1-enps0))*(t1/enps1+(1-t1)/(1-enps1))*(y1-eta2.ravel())*t0\n",
    "    f12 = t0/((enps0**t0)*(1-enps0)**(1-t0))*(eta20.ravel()-eta10.ravel())+t0/((enps0**t0)*(1-enps0)**(1-t0))*(eta21.ravel()-eta11.ravel())\n",
    "    f13 = (eta0_11+eta0_10.ravel())\n",
    "    c1 = np.mean(f11+f12+f13)\n",
    "    b1 = [2,2,1]\n",
    "\n",
    "    f21 = (t0/enps0+(1-t0)/(1-enps0))*(t1/enps1+(1-t1)/(1-enps1))*(y1-eta2.ravel())*t1\n",
    "    f22 = 1/((enps0**t0)*(1-enps0)**(1-t0))*(eta21.ravel()-eta11.ravel())\n",
    "    f23 = (eta0_11+eta0_01.ravel())\n",
    "    c2 = np.mean(f21+f22+f23)\n",
    "    b2 = [2,1,2]\n",
    "\n",
    "    coef = np.linalg.solve(np.array([b0,b1,b2]),np.array([c0,c1,c2]))\n",
    "\n",
    "    phi_dr = (coef[1]+coef[2])\n",
    "\n",
    "\n",
    "    ## MSM with original ps\n",
    "    #puse0 = paramdat['p0']; puse1 = paramdat['p1']\n",
    "    IPW = (t0/enps0+(1-t0)/(1-enps0))*(t1/enps1+(1-t1)/(1-enps1))\n",
    "    msm_lm = linear_model.LinearRegression()\n",
    "    msm_lm.fit(testdat[['t0','t1']],testdat['y1'],sample_weight=IPW)\n",
    "    phi_msm_lm = (np.sum(msm_lm.coef_))\n",
    "\n",
    "    ## bootstrap \n",
    "    dr_boot = []; dr_boot_wo = []; # wo: without re-estimation of nuisance parameters\n",
    "    ps_boot = []; msm_boot = []; msm_b1boot = []; msm_b2boot = []\n",
    "    gcomp_boot = []; gcomplm_boot = []\n",
    "    for i in range(500):\n",
    "        sampleid = np.random.choice(range(1, n+1), size=n, replace=True)\n",
    "        dat_boot = testdat.iloc[sampleid-1, :]\n",
    "\n",
    "        enps0_btwo = ps_predict(dat_boot,ps0feature,baseps0_tr,baseps0_ts,cls_stack0_tr,cls_stack0_ts)\n",
    "\n",
    "        enps1_btwo = ps_predict(dat_boot,ps1feature,baseps1_tr,baseps1_ts,cls_stack1_tr,cls_stack1_ts)\n",
    "\n",
    "        bootdat11 = dat_boot.copy(); bootdat11['t0']=1;bootdat11['t1']=1\n",
    "        bootdat00 = dat_boot.copy(); bootdat00['t0']=0;bootdat00['t1']=0\n",
    "\n",
    "        bootdat1 = dat_boot.copy(); bootdat1['t1']=1\n",
    "        bootdat0 = dat_boot.copy(); bootdat0['t1']=0\n",
    "\n",
    "        bootdat10 = dat_boot.copy(); bootdat10['t0']=1;bootdat10['t1']=0\n",
    "        bootdat01 = dat_boot.copy(); bootdat01['t0']=0;bootdat01['t1']=1\n",
    "\n",
    "\n",
    "        ## G-comp with LR\n",
    "        lm1boot = linear_model.LinearRegression()\n",
    "        lm1boot.fit(dat_boot[iter1feature],dat_boot[iter1outcome])\n",
    "        Q11boot = lm1boot.predict(bootdat11[iter1feature])\n",
    "        Q00boot = lm1boot.predict(bootdat00[iter1feature])\n",
    "\n",
    "        lm0_1boot = linear_model.LinearRegression()\n",
    "        lm0_1boot.fit(dat_boot[iter0feature],Q11boot)\n",
    "        lm0_0boot = linear_model.LinearRegression()\n",
    "        lm0_0boot.fit(dat_boot[iter0feature],Q00boot)\n",
    "        gcomplm_boot.append(np.mean(lm0_1boot.predict(bootdat11[iter0feature])-lm0_0boot.predict(bootdat00[iter0feature])))\n",
    "\n",
    "\n",
    "        # PS\n",
    "\n",
    "        ## MSM\n",
    "        IPWboot = (dat_boot['t0'].values.ravel()/enps0_btwo+(1-dat_boot['t0'].values.ravel())/(1-enps0_btwo))*(dat_boot['t1'].values.ravel()/enps1_btwo+(1-dat_boot['t1'].values.ravel())/(1-enps1_btwo))\n",
    "        msmboot_lm = linear_model.LinearRegression()\n",
    "        msmboot_lm.fit(dat_boot[['t0','t1']],dat_boot['y1'],sample_weight=IPWboot)\n",
    "        msm_boot.append((np.sum(msmboot_lm.coef_))); msm_b1boot.append(msmboot_lm.coef_[0]); msm_b2boot.append(msmboot_lm.coef_[1])\n",
    "\n",
    "        eta2_btwo = gcompu_predict(dat_boot,iter1feature,basemodel1_tr,basemodel1_ts,lm_stack1_tr,lm_stack1_ts)\n",
    "\n",
    "        eta20_btwo = gcompu_predict(bootdat0,iter1feature,basemodel1_tr,basemodel1_ts,lm_stack1_tr,lm_stack1_ts)\n",
    "    \n",
    "        eta21_btwo = gcompu_predict(bootdat1,iter1feature,basemodel1_tr,basemodel1_ts,lm_stack1_tr,lm_stack1_ts)\n",
    "    \n",
    "        eta10_btwo = gcompu_predict(bootdat0,iter0feature,basemodel20_tr,basemodel20_ts,lm_stack20_tr,lm_stack20_ts)\n",
    "    \n",
    "        eta11_btwo = gcompu_predict(bootdat1,iter0feature,basemodel21_tr,basemodel21_ts,lm_stack21_tr,lm_stack21_ts)\n",
    "\n",
    "        eta0_00_btwo = gcompu_predict(bootdat00,iter0feature,basemodel20_tr,basemodel20_ts,lm_stack20_tr,lm_stack20_ts)\n",
    "    \n",
    "        eta0_11_btwo = gcompu_predict(bootdat11,iter0feature,basemodel21_tr,basemodel21_ts,lm_stack21_tr,lm_stack21_ts)\n",
    "\n",
    "        eta0_10_btwo = gcompu_predict(bootdat10,iter0feature,basemodel20_tr,basemodel20_ts,lm_stack20_tr,lm_stack20_ts)\n",
    "    \n",
    "        eta0_01_btwo = gcompu_predict(bootdat01,iter0feature,basemodel21_tr,basemodel21_ts,lm_stack21_tr,lm_stack21_ts)\n",
    "\n",
    "\n",
    "        # DR step\n",
    "        boott0 = dat_boot['t0']; boott1= dat_boot['t1']; booty1 = dat_boot['y1']; #booty0 = dat_boot['y0']\n",
    "        f01_btwo = ((boott0/enps0_btwo+(1-boott0)/(1-enps0_btwo))*(boott1/enps1_btwo+(1-boott1)/(1-enps1_btwo))*(booty1-eta2_btwo.ravel()))\n",
    "        f02_btwo = 1/((enps0_btwo**boott0)*(1-enps0_btwo)**(1-boott0))*(eta20_btwo.ravel()-eta10_btwo.ravel())+1/((enps0_btwo**boott0)*(1-enps0_btwo)**(1-boott0))*(eta21_btwo.ravel()-eta11_btwo.ravel())\n",
    "        f03_btwo = (eta0_00_btwo+eta0_11_btwo+eta0_10_btwo.ravel()+eta0_01_btwo.ravel())\n",
    "        c0_btwo = np.mean(f01_btwo+f02_btwo+f03_btwo)\n",
    "        b0_btwo = [4,2,2]\n",
    "\n",
    "        f11_btwo = (boott0/enps0_btwo+(1-boott0)/(1-enps0_btwo))*(boott1/enps1_btwo+(1-boott1)/(1-enps1_btwo))*(booty1-eta2_btwo.ravel())*boott0\n",
    "        f12_btwo = boott0/((enps0_btwo**boott0)*(1-enps0_btwo)**(1-boott0))*(eta20_btwo.ravel()-eta10_btwo.ravel())+boott0/((enps0_btwo**boott0)*(1-enps0_btwo)**(1-boott0))*(eta21_btwo.ravel()-eta11_btwo.ravel())\n",
    "        f13_btwo = (eta0_11_btwo+eta0_10_btwo.ravel())\n",
    "        c1_btwo = np.mean(f11_btwo+f12_btwo+f13_btwo)\n",
    "        b1_btwo = [2,2,1]\n",
    "\n",
    "        f21_btwo = (boott0/enps0_btwo+(1-boott0)/(1-enps0_btwo))*(boott1/enps1_btwo+(1-boott1)/(1-enps1_btwo))*(booty1-eta2_btwo.ravel())*boott1\n",
    "        f22_btwo = 1/((enps0_btwo**boott0)*(1-enps0_btwo)**(1-boott0))*(eta21_btwo.ravel()-eta11_btwo.ravel())\n",
    "        f23_btwo = (eta0_11_btwo+eta0_01_btwo.ravel())\n",
    "        c2_btwo = np.mean(f21_btwo+f22_btwo+f23_btwo)\n",
    "        b2_btwo = [2,1,2]\n",
    "\n",
    "        coef_btwo = np.linalg.solve(np.array([b0_btwo,b1_btwo,b2_btwo]),np.array([c0_btwo,c1_btwo,c2_btwo]))\n",
    "\n",
    "        dr_boot_wo.append(coef_btwo[1]+coef_btwo[2])\n",
    "\n",
    "\n",
    "    return  phi_data, phi_gcomp, phi_dr,phi_gcomp_lm, phi_msm_lm, dr_boot_wo, msm_boot,msm_b1boot,msm_b2boot,gcomp_boot,gcomplm_boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation with p = 100, effect size = 5\n",
    "from functools import partial\n",
    "start_time = time.time()\n",
    "with multiprocess.Pool(processes=20) as pool:\n",
    "    # phi_data_100bs, phi_gcomp_100bs, phi_dr_100bs, phi_gcomp_lm_100bs, phi_msm_lm_100bs, dr_boot_100bs, dr_btwo_100bs = pool.map(simulation_loop,range(10))\n",
    "    results2 = pool.map(partial(simulation_loop,n=500,p = 100),range(80))\n",
    "    pool.close(); pool.join()\n",
    "\n",
    "end_time = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
